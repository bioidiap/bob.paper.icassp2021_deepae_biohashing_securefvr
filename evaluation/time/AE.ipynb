{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ NOTE: The torch device is: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################load model###############################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"************ NOTE: The torch device is:\", device)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1,16,3,2,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Conv2d(16,32,3,2,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Conv2d(32,64,3,2,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Conv2d(64,128,3,2,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Conv2d(128,256,3,2,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(12* 21* 256,100),\n",
    "            #nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential( \n",
    "            nn.Linear(100,12* 21* 256),\n",
    "            #nn.BatchNorm2d(6*10*128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential( \n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), \n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        embedded_anchor   = self.encoder(anchor)\n",
    "        embedded_positive = self.encoder(positive)\n",
    "        embedded_negative = self.encoder(negative)\n",
    "        \n",
    "        input_to_decoder_anchor   = self.fc(embedded_anchor).view(-1,256,12,21)\n",
    "        input_to_decoder_positive = self.fc(embedded_anchor).view(-1,256,12,21)\n",
    "        input_to_decoder_negative = self.fc(embedded_anchor).view(-1,256,12,21)\n",
    "        \n",
    "        decoded_anchor   = self.decoder(input_to_decoder_anchor)\n",
    "        decoded_positive = self.decoder(input_to_decoder_positive)\n",
    "        decoded_negative = self.decoder(input_to_decoder_negative)\n",
    "        \n",
    "        return decoded_anchor, decoded_positive, decoded_negative, embedded_anchor, embedded_positive, embedded_negative\n",
    "        \n",
    "    def get_embeding(self,x):\n",
    "        return self.encoder(x)\n",
    "        \n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "epoch=67\n",
    "model.load_state_dict(torch.load( '../../model/img/alpha_1/emb_100/model/{}.pth'.format(epoch) , map_location=device))\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start the code\n",
      "preparing data\n",
      "0.05680227279663086\n",
      "(1, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/idiap/temp/hotroshi/anaconda3/envs/bob_env_pytorch/lib/python3.7/site-packages/bob/bio/vein/preprocessor/normalize.py:137: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = numpy.linalg.lstsq(A,bl)[0] # obtaining the parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.058064937591552734\n",
      "(1, 100)\n",
      "0.05633234977722168\n",
      "(1, 100)\n",
      "0.05682253837585449\n",
      "(1, 100)\n",
      "0.06197047233581543\n",
      "(1, 100)\n",
      "0.05721426010131836\n",
      "(1, 100)\n",
      "0.0575101375579834\n",
      "(1, 100)\n",
      "0.05710887908935547\n",
      "(1, 100)\n",
      "0.057004451751708984\n",
      "(1, 100)\n",
      "0.05729341506958008\n",
      "(1, 100)\n",
      "0.0570068359375\n",
      "(1, 100)\n",
      "0.05746054649353027\n",
      "(1, 100)\n",
      "0.0571897029876709\n",
      "(1, 100)\n",
      "0.057146310806274414\n",
      "(1, 100)\n",
      "0.057524681091308594\n",
      "(1, 100)\n",
      "0.05712413787841797\n",
      "(1, 100)\n",
      "0.05710029602050781\n",
      "(1, 100)\n",
      "0.06477642059326172\n",
      "(1, 100)\n",
      "0.06372356414794922\n",
      "(1, 100)\n",
      "0.06109976768493652\n",
      "(1, 100)\n",
      "0.05744528770446777\n",
      "(1, 100)\n",
      "0.05694270133972168\n",
      "(1, 100)\n",
      "0.0570986270904541\n",
      "(1, 100)\n",
      "0.05686330795288086\n",
      "(1, 100)\n",
      "0.05707859992980957\n",
      "(1, 100)\n",
      "0.05698800086975098\n",
      "(1, 100)\n",
      "0.05704069137573242\n",
      "(1, 100)\n",
      "0.05718493461608887\n",
      "(1, 100)\n",
      "0.05694913864135742\n",
      "(1, 100)\n",
      "0.0569915771484375\n",
      "(1, 100)\n",
      "0.05692887306213379\n",
      "(1, 100)\n",
      "0.057051658630371094\n",
      "(1, 100)\n",
      "0.057439565658569336\n",
      "(1, 100)\n",
      "0.05722188949584961\n",
      "(1, 100)\n",
      "0.057209014892578125\n",
      "(1, 100)\n",
      "0.057424068450927734\n",
      "(1, 100)\n",
      "0.05702018737792969\n",
      "(1, 100)\n",
      "0.05716991424560547\n",
      "(1, 100)\n",
      "0.05717182159423828\n",
      "(1, 100)\n",
      "0.057183027267456055\n",
      "(1, 100)\n",
      "0.05726170539855957\n",
      "(1, 100)\n",
      "0.05715775489807129\n",
      "(1, 100)\n",
      "0.0569303035736084\n",
      "(1, 100)\n",
      "0.05739426612854004\n",
      "(1, 100)\n",
      "0.05724024772644043\n",
      "(1, 100)\n",
      "0.057305335998535156\n",
      "(1, 100)\n",
      "0.05715322494506836\n",
      "(1, 100)\n",
      "0.05759310722351074\n",
      "(1, 100)\n",
      "0.056537628173828125\n",
      "(1, 100)\n",
      "0.0567929744720459\n",
      "(1, 100)\n",
      "0.0566859245300293\n",
      "(1, 100)\n",
      "0.056379079818725586\n",
      "(1, 100)\n",
      "0.056467294692993164\n",
      "(1, 100)\n",
      "0.05648183822631836\n",
      "(1, 100)\n",
      "0.0567474365234375\n",
      "(1, 100)\n",
      "0.057080745697021484\n",
      "(1, 100)\n",
      "0.057193756103515625\n",
      "(1, 100)\n",
      "0.05709505081176758\n",
      "(1, 100)\n",
      "0.05691337585449219\n",
      "(1, 100)\n",
      "0.057099103927612305\n",
      "(1, 100)\n",
      "0.057328224182128906\n",
      "(1, 100)\n",
      "0.05714583396911621\n",
      "(1, 100)\n",
      "0.057413578033447266\n",
      "(1, 100)\n",
      "0.05690932273864746\n",
      "(1, 100)\n",
      "0.056919097900390625\n",
      "(1, 100)\n",
      "0.056913137435913086\n",
      "(1, 100)\n",
      "0.057238101959228516\n",
      "(1, 100)\n",
      "0.05710887908935547\n",
      "(1, 100)\n",
      "0.05683732032775879\n",
      "(1, 100)\n",
      "0.057112693786621094\n",
      "(1, 100)\n",
      "0.057028770446777344\n",
      "(1, 100)\n",
      "0.05723834037780762\n",
      "(1, 100)\n",
      "0.056569814682006836\n",
      "(1, 100)\n",
      "0.07310032844543457\n",
      "(1, 100)\n",
      "0.0567929744720459\n",
      "(1, 100)\n",
      "0.05715513229370117\n",
      "(1, 100)\n",
      "0.05695700645446777\n",
      "(1, 100)\n",
      "0.0575413703918457\n",
      "(1, 100)\n",
      "0.05736970901489258\n",
      "(1, 100)\n",
      "0.05703330039978027\n",
      "(1, 100)\n",
      "0.05721020698547363\n",
      "(1, 100)\n",
      "0.056466102600097656\n",
      "(1, 100)\n",
      "0.05727195739746094\n",
      "(1, 100)\n",
      "0.057145118713378906\n",
      "(1, 100)\n",
      "0.056693315505981445\n",
      "(1, 100)\n",
      "0.05700254440307617\n",
      "(1, 100)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9995703d9169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#image, mask = preprocessor(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mimage_and_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/idiap/temp/hotroshi/anaconda3/envs/bob_env_pytorch/lib/python3.7/site-packages/bob/bio/vein/preprocessor/preprocessor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, annotations)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/idiap/temp/hotroshi/anaconda3/envs/bob_env_pytorch/lib/python3.7/site-packages/bob/bio/vein/preprocessor/mask.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0my_lo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_filt_lo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mimg_filt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;31m# Left part of filtered image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/idiap/temp/hotroshi/anaconda3/envs/bob_env_pytorch/lib/python3.7/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(input, weights, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    800\u001b[0m     \"\"\"\n\u001b[1;32m    801\u001b[0m     return _correlate_or_convolve(input, weights, output, mode, cval,\n\u001b[0;32m--> 802\u001b[0;31m                                   origin, True)\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/idiap/temp/hotroshi/anaconda3/envs/bob_env_pytorch/lib/python3.7/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36m_correlate_or_convolve\u001b[0;34m(input, weights, output, mode, cval, origin, convolution)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A sequence of modes is not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m     \u001b[0m_nd_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtemp_needed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"start the code\")\n",
    "import numpy as np\n",
    "from bob.bio.vein.configurations.utfvp import database\n",
    "import bob.io.base\n",
    "\n",
    "from bob.bio.vein.preprocessor import NoCrop, TomesLeeMask, HuangNormalization, \\\n",
    "    NoFilter, Preprocessor\n",
    "\n",
    "preprocessor = Preprocessor(\n",
    "    crop=NoCrop(),\n",
    "    mask=TomesLeeMask(),\n",
    "    normalize=HuangNormalization(),\n",
    "    filter=NoFilter(),\n",
    "    )\n",
    "\n",
    "\n",
    "from bob.bio.vein.extractor import WideLineDetector\n",
    "extractor = WideLineDetector()\n",
    "\n",
    "\n",
    "all_Files = database.objects(protocol='nom', groups='world')\n",
    "    \n",
    "######################################################################    \n",
    "import time \n",
    "all_time=[]\n",
    "\n",
    "for i,obj in enumerate(all_Files[:100]):\n",
    "    path=obj.make_path('/idiap/temp/hotroshi/UTFVP/data','.png')\n",
    "    image = bob.io.base.load(path)\n",
    "    \n",
    "    image_and_mask = preprocessor(image)\n",
    "    \n",
    "    t1= time.time()\n",
    "    finger_image = image# image_and_mask[0]   \n",
    "    finger_mask = image_and_mask[1]\n",
    "    finger_image_ = np.zeros([1,1,finger_image.shape[0]+4,finger_image.shape[1]])\n",
    "    finger_image_[0,0,2:-2,:] = finger_image[:,:]/255.0\n",
    "    finger_image_torch = torch.tensor(finger_image_, requires_grad=False).float().to(device)\n",
    "    feature = model.get_embeding(finger_image_torch).cpu().detach().numpy()\n",
    "        \n",
    "    all_time.append(time.time()-t1)\n",
    "    \n",
    "print(np.mean(all_time[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
